{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab 9.1 Generative Adversarial Network**\n",
    "**NOTE :** Use the dataset from lab5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "Complete the GAN architecture that generates RGB images of size 128x128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=256,im_ch=1,hidden_dim=1024):\n",
    "        super(Generator,self).__init__()\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward(self,noise):\n",
    "        pass\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,im_ch=1,hidden_dim=32):\n",
    "        super(Discriminator,self).__init__()\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward(self,image):\n",
    "        pass\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the function below. The `get_noise` function generates a random noise tensor that is typically used as input to a Generator\n",
    "- `n_sample`: The number of noise samples to generate.\n",
    "\n",
    "- `z_dim`: The dimensionality of each noise vector.\n",
    "\n",
    "- `device`: The device on which the tensor will be allocated. By default, it is set to 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "def get_noise(n_sample,z_dim,device='cuda'):\n",
    "    pass\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 25\n",
    "z_dim = 100\n",
    "noise = get_noise(n_sample, z_dim)\n",
    "assert noise.shape == (n_sample, z_dim), f\"Expected shape {(n_sample, z_dim)}, but got {noise.shape}\"\n",
    "\n",
    "noise_cpu = get_noise(n_sample, z_dim, device='cpu')\n",
    "assert noise_cpu.device.type == 'cpu', f\"Expected tensor to be on 'cpu', but got {noise_cpu.device.type}\"\n",
    "assert noise.dtype == torch.float32, f\"Expected dtype to be torch.float32, but got {noise.dtype}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Prepare all training components such as the dataset, batch size, optimizer, and model, etc. No need to perform a train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display first batch of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `get_noise` to generate noise with 25 samples, and then use the generator to generate images with that noise.\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image.png](https://github.com/Digital-Image-Processing-Laboratory/image_processing-2024/blob/master/Lab9_GAN/assets/1.png?raw=true)\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the training function that trains and logs the average loss for both the generator and discriminator, and generates sample images at each epoch (using the same input vector as the previous part) to [TensorBoard](https://pytorch.org/docs/stable/tensorboard.html).\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output in tensorboard</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image.png](https://github.com/Digital-Image-Processing-Laboratory/image_processing-2024/blob/master/Lab9_GAN/assets/2.png?raw=true)\n",
    "\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "def train(generator, discriminator, gen_opt, disc_opt, criterion, dataloader, test_noise, z_dim, epochs=10, writer=None, checkpoint_path=None, device='cpu'):\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "train(None)\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Genereate the image.\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image.png](https://github.com/Digital-Image-Processing-Laboratory/image_processing-2024/blob/master/Lab9_GAN/assets/3.png?raw=true)\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "1. In the architecture of a discriminator, if the last layer is not a fully connected layer and the output is in a 3D tensor format rather than a 1D vector, how would you compute the Binary Cross-Entropy Loss (BCELoss) in this case?\n",
    "\n",
    "2. If the architecture of the generator includes one or more hidden fully connected layers before the output layer, how would this affect the quality or characteristics of the generated output? \n",
    "\n",
    "3. When alternating between training the generator and the discriminator in a GAN, at which level should this switching occur to achieve optimal resultsâ€”should it be done at the epoch level, the iteration level, or the batch level?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
