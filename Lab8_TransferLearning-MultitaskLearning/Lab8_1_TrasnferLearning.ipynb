{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab 8.1 Transfer Learning & Multitask Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,Subset,Dataset,random_split\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `MultiLanguageHandwrittenDataset` class below. It should return:\n",
    "- `image`: the image data\n",
    "- `label`: the digit label (0-9)\n",
    "- `language`: the language (Thai or English)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "class MultiLanguageHandwrittenDataset(Dataset):\n",
    "    def __init__(self, root_dirs, languages, transforms=None):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.languages = languages\n",
    "        self.transform = transforms\n",
    "        self.samples = []\n",
    "        for root_dir, language in zip(self.root_dirs, self.languages):\n",
    "            for subdir in os.scandir(root_dir):\n",
    "                if subdir.is_dir():\n",
    "                    label = int(subdir.name)\n",
    "                    for file in os.scandir(subdir.path):\n",
    "                        if file.is_file():\n",
    "                            self.samples.append((file.path, label, language))\n",
    "        print(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "            \n",
    "        return image, label, language\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use you `MultiLanguageHandwrittenDataset` here and display the first batch\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image.png](https://github.com/Digital-Image-Processing-Laboratory/image_processing-2024/blob/master/Lab8_TransferLearning-MultitaskLearning/assets/1.png?raw=true)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "root_dirs = [None]\n",
    "languages = [None]\n",
    "\n",
    "dataset = MultiLanguageHandwrittenDataset(None)\n",
    "dataloader = DataLoader(None)\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `customVGG16` class below, which can create a pretrained VGG16 model and customize the number of fully connected (FC) layers. It also allows adding new convolutional layers and unfreezing pretrained layers based on their index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "class customVGG16(nn.Module):\n",
    "    def __init__(self,add_feat_dims=None,h_dims=None,num_classes=10,input_size=(1,28,28),trainable_layers_idx=None):\n",
    "        super(customVGG16, self).__init__()\n",
    "        self.vgg16 = models.vgg16(pretrained=True)\n",
    "        for param in self.vgg16.features[:].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.vgg16.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        if trainable_layers_idx is not None:\n",
    "            for idx in trainable_layers_idx:\n",
    "                for param in self.vgg16.features[idx].parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        ...\n",
    "\n",
    "\n",
    "    def _get_input_size_fc(self, input_shape):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, *input_shape)\n",
    "            x = self.vgg16.features(x)\n",
    "            x = self.vgg16.avgpool(x)\n",
    "            x = torch.flatten(x[0])\n",
    "            return x.size(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        return x\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage\n",
    "```\n",
    "trainable_layers_idx = [-1,-2,-3,-4,-5]\n",
    "model = customVGG16(add_feat_dims=[512],h_dims=[512,256,256],input_size=(3,224,224),trainable_layers_idx=trainable_layers_idx)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `train` function below, which logs Loss/train, Accuracy/train, Loss/test, and Accuracy/test to [TensorBoard](https://pytorch.org/docs/stable/tensorboard.html).Then, complete the evaluate_task function, which prints the classification report and plots the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "def train(model,opt,loss_fn,train_loader,val_loader,epochs=10,writer=None,checkpoint_path=None,device='cpu',task='digit'):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_task(y_true, y_pred, task_name=\"Task\"):\n",
    "    pass\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning for Digit classification task\n",
    "Declare the `customVGG16` model with custom layers of your choice. Then, split the dataset into training, validation, and test sets, and proceed to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "model1 = customVGG16(None)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = None\n",
    "\n",
    "writer = None\n",
    "opt = None\n",
    "loss_fn = None\n",
    "train(None)\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use `evaluate_task` to evlauate you model1 here.\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "```\n",
    "Digit - Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.77      0.92      0.84        26\n",
    "           1       0.75      0.94      0.83        32\n",
    "           2       0.66      0.54      0.59        39\n",
    "           3       0.76      0.54      0.63        35\n",
    "           4       0.68      0.53      0.60        47\n",
    "           5       0.52      0.42      0.47        33\n",
    "           6       0.59      0.88      0.71        33\n",
    "           7       0.46      0.59      0.52        27\n",
    "           8       0.70      0.65      0.67        43\n",
    "           9       0.85      0.83      0.84        35\n",
    "\n",
    "    accuracy                           0.67       350\n",
    "   macro avg       0.67      0.68      0.67       350\n",
    "weighted avg       0.68      0.67      0.67       350\n",
    "\n",
    "```\n",
    "\n",
    "![image.png](https://github.com/Digital-Image-Processing-Laboratory/image_processing-2024/blob/master/Lab8_TransferLearning-MultitaskLearning/assets/2.png?raw=true)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning for Language classification task\n",
    "Declare a NEW `customVGG16` model with custom layers of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "model2 = customVGG16(None)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = None\n",
    "\n",
    "writer = None\n",
    "opt = None\n",
    "loss_fn = None\n",
    "train(None)\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use `evaluate_task` to evlauate you model2 here.\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "```\n",
    "Language - Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.99      0.96       175\n",
    "           1       0.99      0.93      0.96       175\n",
    "\n",
    "    accuracy                           0.96       350\n",
    "   macro avg       0.96      0.96      0.96       350\n",
    "weighted avg       0.96      0.96      0.96       350\n",
    "\n",
    "```\n",
    "\n",
    "![image.png](https://github.com/Digital-Image-Processing-Laboratory/image_processing-2024/blob/master/Lab8_TransferLearning-MultitaskLearning/assets/3.png?raw=true)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `customVGG16_multitask` class below, which can create a pretrained VGG16 model and customize the number of fully connected (FC) layers. It also allows adding new convolutional layers and unfreezing pretrained layers based on their index. Additionally, it allows branching the model into two heads for multitask learning, where one head handles digit classification, and the other handles language classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customVGG16_multitask(nn.Module):\n",
    "    def __init__(self,add_feat_dims=None,h_dims=None,input_size=(1,28,28),trainable_layers_idx=None):\n",
    "        super(customVGG16_multitask, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def _get_input_size_fc(self, input_shape):\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, *input_shape)\n",
    "            x = self.vgg16.features(x)\n",
    "            x = self.vgg16.avgpool(x)\n",
    "            x = torch.flatten(x[0])\n",
    "            return x.size(0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.vgg16.digit(x)\n",
    "        out2 = self.vgg16.lang(x)\n",
    "\n",
    "        return out1,out2\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the `train_multi` function below, which train multitask model and  logs Loss/train, Accuracy/train, Loss/test, and Accuracy/test to [TensorBoard](https://pytorch.org/docs/stable/tensorboard.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multi(model, opt, loss_fn, train_loader, val_loader, epochs=10, writer=None, checkpoint_path=None, device='cpu'):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "model = customVGG16(None)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = None\n",
    "\n",
    "writer = None\n",
    "opt = None\n",
    "loss_fn = None\n",
    "train(None)\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use `evaluate_task` to evlauate you model here.\n",
    "<details>\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "```\n",
    "Digit - Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.89      0.86        35\n",
    "           1       0.81      0.91      0.85        32\n",
    "           2       0.76      0.55      0.64        40\n",
    "           3       0.53      0.66      0.58        32\n",
    "           4       0.54      0.29      0.38        24\n",
    "           5       0.51      0.57      0.54        37\n",
    "           6       0.68      0.72      0.70        29\n",
    "           7       0.60      0.71      0.65        34\n",
    "           8       0.62      0.71      0.66        48\n",
    "           9       0.68      0.49      0.57        39\n",
    "\n",
    "    accuracy                           0.65       350\n",
    "   macro avg       0.66      0.65      0.64       350\n",
    "weighted avg       0.66      0.65      0.65       350\n",
    "\n",
    "```\n",
    "\n",
    "![image.png](https://github.com/Digital-Image-Processing-Laboratory/image_processing-2024/blob/master/Lab8_TransferLearning-MultitaskLearning/assets/4.png?raw=true)\n",
    "\n",
    "```\n",
    "Language - Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.98      0.98       172\n",
    "           1       0.98      0.98      0.98       178\n",
    "\n",
    "    accuracy                           0.98       350\n",
    "   macro avg       0.98      0.98      0.98       350\n",
    "weighted avg       0.98      0.98      0.98       350\n",
    "```\n",
    "\n",
    "![image-2.png](https://github.com/Digital-Image-Processing-Laboratory/image_processing-2024/blob/master/Lab8_TransferLearning-MultitaskLearning/assets/5.png?raw=true)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question\n",
    "1. If you build two separate models, one for each task with a different classification problem, \n",
    "how does the overall model size of two separate models compared to a single model with shared layers and two classifiers \n",
    "at the end?\n",
    "\n",
    "2. In what scenarios might a single model with two classifiers outperform two separate models in terms of generalization? Is there a risk of one task negatively affecting the other?\n",
    "\n",
    "3. How can weighted loss functions be applied in a single model with two classifiers to balance the performance of both tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
